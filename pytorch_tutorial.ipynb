{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ucCDs0OxHjb"
      },
      "outputs": [],
      "source": [
        "# install pytorch then import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgfM1W583uft"
      },
      "source": [
        "# Basic Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRZYhW-k3UFN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE5OXIAo3Vzd",
        "outputId": "ae988910-f681-4c0b-8063-02b8dd609793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.7966e-29,  4.4322e-41,  2.3140e-33])\n"
          ]
        }
      ],
      "source": [
        "x = torch.empty(3) # create 1D tensor of size 3; add more numbers for higher dimensions\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaXx1ciU3sWn",
        "outputId": "352de67c-de2d-454b-d6c3-f761c04ae8a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0487, 0.8774, 0.9829],\n",
            "        [0.8283, 0.6321, 0.5960],\n",
            "        [0.5476, 0.6583, 0.4423],\n",
            "        [0.6647, 0.8722, 0.7679],\n",
            "        [0.9290, 0.7206, 0.2262]])\n",
            "tensor(0.6321)\n",
            "tensor([0.9829, 0.5960, 0.4423, 0.7679, 0.2262])\n",
            "tensor([0.8283, 0.6321, 0.5960])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(x[1, 1])\n",
        "print(x[:, 2])\n",
        "print(x[1, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbpBNPVG5iQJ",
        "outputId": "e8738e1a-c727-4b06-f600-679231e1b615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.3199, 0.3054, 0.1873, 0.7865],\n",
            "        [0.9565, 0.2925, 0.6158, 0.0753],\n",
            "        [0.2853, 0.1798, 0.9922, 0.2626],\n",
            "        [0.8066, 0.4766, 0.8138, 0.3130]])\n",
            "tensor([0.3199, 0.3054, 0.1873, 0.7865, 0.9565, 0.2925, 0.6158, 0.0753, 0.2853,\n",
            "        0.1798, 0.9922, 0.2626, 0.8066, 0.4766, 0.8138, 0.3130])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(4, 4)\n",
        "print(x)\n",
        "y = x.view(16) # puts tensor values in one dimension\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH4tp8Hh51aM",
        "outputId": "ebb9de2b-6e56-423b-c8c3-4498a1f09078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "a.add_(1) # will modify both a and b if on CPU\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# changing from numpy to tensor is same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_XeG_ph7TD7"
      },
      "outputs": [],
      "source": [
        "# create tensor on gpu (2 diff ways)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    x = torch.ones(5, device=device)\n",
        "    y = torch.ones(5)\n",
        "    y = y.to(device)\n",
        "    z = x + y # will be performed on the GPU so may be much faster\n",
        "    z.numpy() # will not work because numpy cannot handle GPU tensors\n",
        "    z = z.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czZiViJH82Vk",
        "outputId": "b6726962-d4c1-4b5d-9be5-8cfddfe9cf59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(5, requires_grad=True) # by defualt false; used for optimization\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDmrSwmbhFdD"
      },
      "source": [
        "# Autograd Package and Calculating Gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NitCP1dChFKd"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-a4bIGuhNo7",
        "outputId": "2ddbef3f-2707-4fec-bc56-2b5fcd9f77a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.3205, -0.3937, -0.8773], requires_grad=True)\n",
            "tensor([2.3205, 1.6063, 1.1227], grad_fn=<AddBackward0>)\n",
            "tensor([10.7697,  5.1605,  2.5208], grad_fn=<MulBackward0>)\n",
            "tensor(6.1503, grad_fn=<MeanBackward0>)\n",
            "tensor([3.0940, 2.1418, 1.4969])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "print(y)\n",
        "z = y * y * 2\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "z.backward() # dz/dx\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNzToLm_mcOe",
        "outputId": "e5631abc-0319-4566-94ed-06d1cb4c96da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.2028,  1.3495, -0.3696])\n",
            "tensor([-0.2028,  1.3495, -0.3696])\n",
            "tensor([1.7972, 3.3495, 1.6304])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "x.requires_grad_(False) # stops tracking history\n",
        "print(x)\n",
        "x.detach() # same as above; makes copy\n",
        "print(x)\n",
        "with torch.no_grad(): # same as above\n",
        "    y = x + 2\n",
        "    print(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsfBHV0Tmz8Q",
        "outputId": "ebc33a53-6849-445b-c007-7f039d1eac88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ],
      "source": [
        "# dummy\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    model_output = (weights*3).sum()\n",
        "\n",
        "    model_output.backward()\n",
        "\n",
        "    print(weights.grad)\n",
        "\n",
        "    weights.grad.zero_() # resets gradients to zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFfJw7AUn2HQ"
      },
      "outputs": [],
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD([weights], lr=0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLXd-1GZoE7t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN0J1XnfpgwW"
      },
      "source": [
        "# Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wtPDK2Gpjnn"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ou1FzUWq3_1",
        "outputId": "6438f4e4-5e87-4142-b8d5-7339a72abf2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass and compute the loss\n",
        "y_hat = w * x\n",
        "loss = (y_hat - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "# update weights\n",
        "# next forward and backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgzWR6gVnGp0"
      },
      "source": [
        "# Gradient Descent Using Autograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSpUSjlcnMN9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
